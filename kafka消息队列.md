#### 1|消息队列：消息队列可以用来解决什么问题？

一直以来，消息队列都是业界用于构建高并发、高可用系统的利器。即便是简单的业务开发，也可以通过消息队列的解耦、异步特性来提高性能的可用性。

消息队列和数据库、缓存并列为面试中最热门的三个中间件。消息队列本身的知识也很多，理论和实践结合紧密，也是面试中的难题。

**前置知识**

消息队列最鲜明的特性是**异步、削峰、解耦。**也有人说这是消息队列的使用场景、用途，并且二外加了几个，比如日志处理和消息通讯。但实际上，日志处理和消息通讯可以看作是消息队列的具体落地案例。比如日志处理同时利用了消息队列异步、解耦和削峰的特性。

![image-20240508101224110](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508101224110.png)

消息通讯是即时通讯之类的工具，比如说你使用微信、QQ都是通讯工具。通讯工具主要利用的是异步和解耦特性，不过要是你觉得你的通讯工具会有高并发的收发消息场景，也可以看作是削峰。

![image-20240508101537076](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508101537076.png)

基本上一切消息队列的应用场景，都是围绕异步、解耦和削峰三个特性来设计的。反过来也可以说，如果你有一些需要异步、解耦和削峰的需求，那么消息队列就是最合适的工具。

此外消息队列还可以用来实现事件驱动结构。

**面试准备**

在准备消息队列面试的时候，你需要搞清楚下面几点：

- 你们公司用没有使用消息队列？主要用于解决什么场景的问题？
- 如果使用了消息队列，那么在具体的场景下不使用消息队列是否可行？和使用消息队列的方案比起来，有什么优缺点？
- 你们公司用的是什么消息队列，它有什么优缺点？

在前置知识里面提高了消息队列的三个特性：异步、解耦和削峰。可以在公司内部，或者自己的过往工作经验里面各找一个案例。虽然我提到过，一个案例可能同时体现了异步、解耦和削峰三个特性，但是也需要准备多几个案例，准备得更充分一些。

面试管如果问到了下面这些问题，你都可以直接用下面的内容回答，或者引导到这里。

- 你有没有用过消息队列？用来解决什么问题？你是否听说过延时队列？怎么实现延时队列？
- 然后设计一个秒杀架构？在回答的时候可以强调一下消息队列的作用。什么是事件驱动架构？

建议有机会的话，在遇到一些非常复杂棘手的业务时，可以考虑使用事件驱动来解决。个人认为越复杂的业务系统，应用事件驱动就越有价值。

**基本思路**

首先在简历上你就应该写上擅长消息队列或者说自己能够用消息队列解决问题。
后续面试官在提问的时候就会考虑消息队列这方面的内容。面试官可能会先问你用消息队列解决过什么问题，那么你回答准备的案例就可以。

在介绍了案例之后，面试官大概率会问一个问题，就是在具体的场景下，你为什么非得使用消息队列？

在前置知识里面已经解释了两个场景：日志处理和消息通讯。这里在补充几个。
这些场景都是那种引导性非常强的场景，可以把话题引导到别的主题下。

**秒杀场景**

秒杀也是面试中的一个大热点。一般秒杀的架构设计中都会使用消息队列，同时利用消息队列三个特性。

下面是简单的秒杀结构图：

![image-20240508110924296](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508110924296.png)

在消息队列之前，要对用户请求做一些校验，比如说这个用户是否已经参加过秒杀了。其次要扣库存，扣库存成功才算抢到了。紧接着就是把这个请求丢到消息队列里，后续异步创建订单，并且完成支付。

那么这种设计的精髓就是利用消息队列把整个秒杀过程分成轻重两个部分。

- 在进入消息队列之前的操作都是轻量级的，一般也就是内存计算或者范文一些Redis，所以你可以任务瓶颈取决于Redis的性能。
- 而进入消息队列之后就是非常重量级的操作了，比如要进一步验证交易的合法性，操作数据库等。

![image-20240508111545561](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508111545561.png)

所以你就可以这样介绍秒杀方案，关键词是**轻重之分**。

> ​		消息队列还经常被用在秒杀场景里面。最基本的架构就是秒杀请求进来之后，会有一个轻量级的服务。这个服务就是做一些限流、请求校验和库存扣减的事情。这些事情差不多都是内存操作，最多操作Redis。当库存扣减成功之后，就会把秒杀请求丢到一个消息队列。
>
> ​		然后订单服务会从消息队列里面将请求拿出来，真正创建订单，并且提示用户支付。这一部分就是重量级的操作。

这个场景介绍完，面试管就可能进一步问你和秒杀相关的内容，比如说扣减了库存之后，万一用户没有支付怎么办，于是你就可以用下面这个案例了。

**订单超时取消**

在电商里面，如果用户下单之后一直没有支付，那么这个订单就会被取消，从而释放库存。

订单超时取消在行业内有很多种做法，这里介绍使用消息队列的解决方案。要想利用消息队列实现订单超时取消功能，需要使用**延时消息。**所谓的延时消息，就是发送者在发送之后，要过一段时间，消费者才能消费的消息。

![image-20240508154249823](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508154249823.png)

你可以这样介绍你的方案。

> ​		消息队列也可以用于订单超时取消这种场景。在这种场景下，我们可以准备一个延时队列，比如说超时时间是30分钟，那么延时也是30分钟。

> ​		但是消费的时候要小心并发问题，就是在30分钟这时刻，一边用户支付，一边消费者也消费超时消息，就会有并发问题、解决思路有很多，可以使用分布式锁、乐观锁，也可以使用SELECT FOR UPDATE锁住订单，防止并发操作。

![image-20240508154955986](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508154955986.png)

这里提到的并发问题，在解决并发问题的思路中，提到了之前数据库部分学到的SELECT FOR UPDATE和乐观锁，乐观锁方案的关键步骤。乐观锁方案就是在你把订单更新为超时状态的时候，需要确保原始状态还是未支付。

```
UPDATE `order` SET `status` = "超时未支付" WHERE `id` = 123 AND `status` = "未支付"
```

类似地，在支付那边也需要确保只有在status是未支付的时候才能发起支付。

这个场景主要是把话题引导到延时消息，延时消息我们后边会纤细分析。目前主流的消息队列中RocketMQ是支持延时消息的，它有插件支持。但是kafka不支持，不过后续会使用Kafka支持延时消息。

**亮点方案**

第一个亮点回答是为什么一定要使用消息队列。前面讲了消息队列广泛应用于各种场景，那么有没有思考过，为什么非得使用消息队列呢？不使用消息队列会怎么样？用了又有什么好处？

**为什么一定要使用消息队列？**

这个问题本身也是反直觉的，也就是因为业界一直说消息队列很好很好，那么如果没有思考过这个问题，面试管突如其来问一下，就不知道怎么回到了。

我们从创建订单的典型场景看起。在订单创建之后，要通知很多下游，正常做法都是发送一个订单创建的消息，然后关系订单创建的业务各自去订阅这个消息就可以了。

这里面试官就会问，为什么订单服务不直接调用各个业务方呢？

![image-20240508163157571](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508163157571.png)

![image-20240508163208594](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508163208594.png)

类似的场景还有，在消息通讯里面为什么服务端不直接把消息转发给各个接受者呢？

![image-20240508163255257](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508163255257.png)

这一类的问题，本质都是在问：在这个业务场景下，不异步、不解耦或者不削峰会有什么问题？

那么不用消息队列究竟有什么问题呢？答案是性能差、拓展性差、可用性差。

这里有一个不太好的回答，就是耦合严重。这个回答只能说你答了，但是回答得不到位。毕竟你没有解耦自然就是耦合严重，所以面试官希望你深入解释的是耦合严重会带来什么后果。你其实可以这么说：

> ​		同步调用方案相比引入消息队列有三个缺陷，分别是性能差、可拓展性差和可用性差。

**性能差**

性能差是因为你需要停下来等全部调用完成才可以返回响应。

![image-20240508164035554](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508164035554.png)

> ​		业务放必须停下来等待结果，如果我这里需要通知三个下游，那么就需要发起三次调用，并且等它们各自的返回结果之后才能继续往下执行，或者返回响应，这样性能太差了。

紧接着面试段就可能和你抬杠：“如果我并发调用呢？性能也很好啊！”他隐含的意思就是你可以开启多个线程或者协程，并发调用所用的下游。

![image-20240508164438912](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508164438912.png)

但是，即便是**并发调用性能也比使用消息队列差。**

> ​		并发调用相比于使用消息队列，性能也更差。在并发调用的情况下，性能取决于最坏的那个同步调用什么时候返回结果。而正常我们丢一个消息到消息中间件上是很快的。

紧接着你可以补充一点，引出拓展性和可用性的话题。

> ​		并且，即便并发调用的性能损耗是可以接受的，但是拓展性和可用性还是解决不了。

**拓展性**

拓展性归根结底就是一句话：如果一下新的下游要接入进来有多难？在使用消息队列的时候，新的下游要接入，只需要自己去订阅消息就可以，完全不需要通知任何人。在公司里，可能就是你丢给下游一个文档，下游自己看看文档，知道订阅哪个topic，消息生产速率有多高，差不多就能自己完成接入了。

![image-20240508165953905](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508165953905.png)

但是如果是同步调用，事情就麻烦很多。你需要下游提供RPC服务地址（定位信息），根据下游的API设计构造请求、处理响应，再一起来联调、测试、上线，遇到了BUG害的推诿扯皮一番。

![image-20240508170136861](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508170136861.png)

所以这里可以这样回答：

> ​		在使用消息队列的情况下，消息发送者完全不关心谁会去消费这些消息。同样地，如果有一个新的业务要订阅这个消息，它可以自主完成。而同步调用的时候，上游必须知道下游的接口，然后要知道如何构造请求、然后解析响应，还要联调、测试、上线，整个过程都得和下游密切合作，因此效率特别低，可拓展性很差。

但是这里你可以刷一亮点，就是在类似的场景下，如果因为一些业务情况确实不能使用消息对了，那么可以考虑提供一个一致性的抽象来减轻这种接入的负担。

> ​		如果在某些场景下确实不能使用消息队列，那么这个拓展性问题可以通过一些技术手段来缓解。比如说上游提供一整套的对接规范，包括API定义、请求和响应中每个字段的含义。这样下游就对着这些API定义来提供实现，上游就不需要适配每一个下游了。

![image-20240508171440032](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508171440032.png)

然后你进一步总结。

> ​		这是对接众多下游的基本设计，可以充分保障高可拓展性和高研发效率。

**可用性**

在使用消息队列的方案中，你只需要确保自己把消息发送到了消息队列上，就认为操作已经成功了。

但是，在同步调用方案中，你必须要确保调用所有的下游都成功了才算成功，所以你还需要额外考虑部分成功部分失败问题。

比如说在订单的例子里面，如果同步调用到推荐成功，但是审计和搜索失败了，那么该怎么办？

所以这样来看，相比使用消息队列的方案，同步调用的方案更加容易出错，并且容错也更难。

**事件驱动**

事件驱动（Event-Driven）可以说是一种软件开发模式，也可以看作是一种架构。它的核心思想是通过把系统看作一系列事件的处理过程，来实现对系统的优化和重构。

可以直观地理解成，整个系统不同组件之间的通信是通过事件来完成的。也就是组件1发送一个事件到消息队列上，然后组件2消费这个消息。组件2消费完成后再发出一个消息到消息队列。每一个事件就是一个消息。

![image-20240508172849112](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508172849112.png)

这些消息可能有不同的Topic，也可能发送到不同的消息队列集群。但是毫无疑问TM要通过密切合作来解决一个业务问题。

它的优点十分明显。

- 低耦合性：每个组件只依赖消息队列，组件之间通过消息的定义间接的耦合在一起。换句话来说，组件爱你只需要知道消息的定义，并不需要知道发送消息的组件是哪个。
- 可拓展性：事件驱动的应用程序具有很强的拓展性，可以通过添加新的事件处理程序、组件等来实现系统的拓展和升级。

- 高可用：可以充分利用消息队列的可靠性、可重复消费特性，来保证消息发送、消费高可用，从而保证整个系统的高可用。

事件驱动适合用来解决一些**复杂、步骤繁多、流程冗长**的业务问题。在下面的亮点方案里面，我用的就是事件驱动结合SAGA分布式事务的方案。这个方案足够高级、冷僻、奇异。它原本用在一个大规模的分布式系统里面，是一个高性能和高可用的分布式事务解决方案。

你可以看一下事件驱动和SAGA结合之后的形态。

![image-20240508173626650](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508173626650.png)

也就是说，当某一个步骤完成之后，就发出一个或者多个事件，驱动事务中的后续步骤。包括回滚也是这样，比如说发出一个代表某一个步骤执行失败的事件，对应的消费者就会去执行反向补偿步骤。

![image-20240508173833004](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508173833004.png)

使用事件驱动的优点是低耦合、高拓展性、异步、高可用。不过在实时性上要比同步调用差一点。我用一个最简单的例子解释它的运作。比如你有一个分布式事务，就是要求先更新DB，在更新缓存。那么在缓存更新失败的场景下，过程看起来就像图里展示的这样。

![image-20240508174054675](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508174054675.png)

其中还原DB是指你需要用原始数据更新回去，而不是数据库回滚操作，我之前在SAGA分布式事务里面就讲过。当然，这个例子知识帮助你理解，正常来说这么简单的分布式事务是用不着SAGA的。

你可以开了这样介绍方案：

> ​		之前我们公司用事件驱动实现了SAGA的分布式事务解决方案。基于事件驱动的SAGA模式就是在每一个步骤结束之后发送事件，不同的步骤会发送一个或多个事件。然后消费者消费了消息之后，就开始执行下一个步骤。比如在更新DB再更新缓存的场景里就可以这样用。这种形态和一般的事务比起来，优势是低耦合、高拓展、高可用。

在这个方案里面，面试官可能追问的方向有两个，一个是分布式事务，另外一个方向是后面要讨论的问题，就是怎么做到消息的可靠发送和可靠消费。

**面试思路总结**

今天主要的内容比较简单，主要介绍了消息队列的三个用途：解耦、异步、削峰，还有几个使用消息队列的场景，包括日志处理、消息通讯、秒杀场景和订单超时取消。希望能从这些场景领悟到消息队列适合解决什么样的问题。

![image-20240508174946701](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240508174946701.png)

#### 2|延时消息：怎么在Kafka上支持延迟消息？

延迟消息在Kafka面试里面是非常热门的，其他消息队列多少也会问，但是不如Kafka问的频繁。因为Kafka不支持延时消息是大家都知道的。但是偏偏Kafka又用得多，很多业务场景要求使用延时消息，因此面试的时候延时消息就成了一个重要的考察点。

和之前的面试点不同，能不延迟消息的方案讲得透彻的人就不多，更不要说刷亮点了。今天就深入延迟消息，并且给出一个非常高级的方案。这个方案会涉及到分库分表，所以能帮助你把这些知识融会贯通。

**延迟队列和延时消息**

延迟队列是一种特殊的队列。它里面的每个元素都有一个过期时间，当元素还没到过期时间的时候，如果你试图从队列里面获取一个元素，你会被阻塞。当有元素过期的时候，你就会拿到这个过期的元素。你就可以这样想，你拿到的永远是最先过期的那个元素。

很多语言本身就提供了延迟队列的实现，比如说在Java里面的DelayQueue。

我们讨论的就是一种特殊形态的延迟队列，或者说是基于消息队列的延迟队列，也叫做延迟消息。具体来说，延迟消息是指消息不是立刻被消费的，而是在经过一段时间之后，才会被消费。在到时间之前，这个消息一直都被存储在消息队列的服务器上。上面提到的订单超时取消的例子，它就用到了延迟消息。

**支持延迟消息和其他消息队列**

目前，大部分云厂商版本呢的消息队列都支持了延迟消息，不过我们这里讨论的是原生支持的消息队列。如果你本身使用了今天我们介绍的这些中间件，那么你可以直接使用这些内容来面试。如果你使用的是Kafka，那么你在面试的时候要注意结合着这些消息队列，对比着面试。

RabbitMQ有插件支持延迟消息功能，而RocketMQ和Kafka则只能自己研发。

**RabbitMQ**

RabbitMQ有一个延迟消息的插件rabbitmq_delayed_message_exchange，只需要启用这个插件就可以使用延迟消息。这个插件的基本原理也比较简单，就是实现了一个exchange。这exchange控制住了消息什么时候会被真的投递队列里。

![image-20240509095730758](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240509095730758.png)

如上图所示，消息会先暂时存储在exchange里面。它使用的是Mnesia来存储，如果不清楚Mnesia是什么，就直观地把它看作一个基于文件的数据库。

当延迟的时间满足条件之后，这些存储的数据就会被投递到真正的消息队列里面。紧接着消费者就可以消费到这个消息了，你可以从这里得到一个启发，就是如果要实现一个延迟队列，是可以借助数据库的。

那么这个插件本身也是有很多限制的，在它的官网主页里面就有说明，其中有两个最突出的限制。

- 消息在真的被投递到目标消息队列之前，是存放在接收到了这个消息的服务端本地的Mnesia里面。也就是说，如果这个时候还没有刷新磁盘，那么消息就会丢失；如果这个节点不可用了，那么这个消息也同样会丢失。
- 不支持高并发、大数据量。显然，现实中很多场景都是要在高并发大数据量下使用延迟消息的，比如前面说的订单超时取消。因此这个缺点也限制了这个插件被广泛使用。

除了这个插件，开发者也可以自己手动实现延迟消息。这就要利用到RabbitMQ的ttl功能和所谓的死信队列了。死信队列时一种逻辑上的概念，也就是说它本身知识一个普通的队列。而死信的意思是指过期的无法被消费的消息，这些消息会被投送到这个死信队列。

简单来说，就是开发者准备了一个队列delay_queue，为这个delay_queue设置过期时间，这个delay_queue不需要消费者。然后把你真是的业务biz_queue绑定到这个delay_queue，作为它的死信队列。

![image-20240509115755872](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240509115755872.png)

生产者发送消息到delay_queue，因为没有消费者，所以消息会过期。过期之后的消息被转发到死信队列，也就是biz_queue里面。这时候消费者就能拿到消息了。

**面试准备**

在准备延迟消息面试的时候，需要先弄清楚公司内部的一些情况。

- 所在的公司有没有使用延迟消息的场景？
- 所在的公司消息中间件支不支持延迟消息？
- 延迟消息的QPS有多高，消息量有多大？延迟时间有多长？

然后，在面试中聊到下面这些话题的时候，你可以尝试把话题引导到这里。

- 如果你介绍你的业务的时候，提到了需要延迟消息的场景，就像上面的订单超时取消的例子，那么你就可以深入讨论延迟消息是怎么实现的。
- 如果吗聊到了Kafka，在介绍它的优缺点的时候，你说一说它的缺点，就是不支持延迟队列，那么面试官就会问你如果要Kafka支持延迟队列应该怎么做。
- 如果聊到了公司使用的消息队列，但并不是Kafka，你们同样可以尝试引导到这里，比如说强调当初MQ技术选型的时候，考虑到Kafka不支持延迟消息，所以最终没有选择Kafka。

**基础思路**

这里我给出了很多比较简单的方案，你可以从这些方案选择一个作为公司的方案，其他方案就作为了解但没有时间过的方案。

**利用定时任务调度**

利用定时任务来实现延迟消息是最好、最简单的方法。对于一个延迟消息来说，应该延迟到30分钟才可以被消费的消息，也可以认为是30分钟后才可以发送。也就是说，你可以设定一个定时任务，这个任务会在30分钟后把消息发送到消息服务器上。

![image-20240509140341799](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240509140341799.png)

所以你可以这么介绍这个方案。

> ​		最简单的做法就是利用定时任务，最好是解决了持久化的分布式任务平台，那么业务发送者就相当于注册了一个任务，这个任务就是在30分钟之后发送一条消息到Kafka上。之后业务消费者就能够消费了。

同时你还可以阐述一下这个方案的缺点。

> ​		这个方案的最大缺点就是支撑不住高并发。这是因为绝大多数定时任务中间件都没办法支撑住高并发、大数据的定时任务调度，所以只有应用规模小，延迟消息也不多的话，才可以考虑使用这个方案。如果想要支持高并发、大数据的延迟方案，还是要考虑利用消息队列。

**分区设置不同延迟时间**

这种应该算很简单的，而且也很好用的方案。你可以看一下它的基本架构图。

![image-20240509144640145](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240509144640145.png)

这里关键的角色是delay_topic和延迟消费组

- delay_topic里面的分区被用来接收不同延迟时间的消息。比如说在上图中分成了p0、p1、p2三个分区，分别用来接收延迟时间为1min、3min和10min的消息。
- 延迟消息组会创建出和分区数量一样的消费者，每一个消费者消费一个分区。消费者每次读取一个消息，等延迟足够长的时间之后，就会转发给biz_topic。

因此对于业务发送者来说，他们需要分解自己的延迟时间来选择正确的分区。而业务消费者则是对整个过程是无感的，也就是说他们并不知道中间有延迟消费者在做转发的事情。

所以可以简单介绍这个方案。

> ​		我们公司用的方案是比较简单的，也就是创建了一个delay_topic，这个topic有N个分区，每个分区设定了不同的延迟时间。然后我们创建了一个消费组去消费这个delay_topic，每个分区有一个独立的消费者。每个消费者读取到一条消息之后，就会根据消息里面的延迟时间来等待一段时间。等待完之再把消息发送到业务真正的topic上。

注意这个N很灵活，可以有多种选择。

- 5个分区：延迟时间设置不同
- 10个分区：延迟时间设置不同

接下来就是刷亮点的地方，第一个就是rebalance问题。

**rebalance问题**

在这个方案中，因为消费者睡眠了不会消费消息，所以Kafka就会判定这个消费者已经崩溃了，就会触发rebalance。发生rebalance之后，等消费者再回复过来，就不知道又被分配到哪个分区，那么之前的睡眠就可以认为是白睡了。

![image-20240509171352033](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240509171352033.png)

为了避免这个问题，就需要确保睡眠期间不会触发rebalance。因此需要利用Kafka的暂停（Pause）功能，在睡眠结束之后，再恢复（resume）。注意，kafka的暂停功能相当于拉取0条数据，并不是不拉数据，也就是说还是会发起Poll调用。

所以整体逻辑就是这样的：

- 拉取一条消息，假如说offset = N，查看剩余的延迟时间t。
- 暂停消费，睡眠一段时间t。
- 睡眠结束之后，恢复消费，继续从offset = N开始消费。

如果面试官没有做过类似的事情的话，可能想不到这里还有坑，所以我建议你主动补充说明，关键词是**rebalance**。

> ​		这个方案里面，要注意一个rebalance的问题。因为每次我们拉取到消息之后，都要根据消息的剩余延迟时间，睡眠一段时间。在这段时间之内，kafka会认为消费者已经崩溃了，从而触发rebalance。等睡眠结束之后，重新消费，就不一定还是消费原来的那个分区了。
>
> ​		所以为了避免这个问题，在睡眠之前，要暂停消费，恢复之后重新消费。重新消费的时候，要注意吧offset重置为之前拉取那个消息的offset。

这个时候，你还可以进一步刷亮点，就是暂停的时候还是会发出Poll调用，只不过不会真的把数据从服务端拉到消费者那里。

> ​		kafka的暂停消费，并不是不再发起Poll请求，而是Poll了但是不会真的拉消息。这样可以让kafka始终认为消费者还活着。

这个rebalance问题还是不太容易想到，但是一致性问题，面试官就很容易想到了。

**一致性问题**

前面说的最好几个步骤是从服务端拉取到消息，然后转发到biz_topic里面。那么你应该意识到这里面涉及到了一个关键问题，是先提交消息，还是先转发？

> ​		这里提交是指biz_topic提交确认转发完毕。因为转发过程是延迟消费者后台线程执行的，主线程只需要收到确认就行。这里想问的是：biz_topic在转发完后提交确认还是先提交确认再进行具体的转发操作？

如果是先提交，那么就会出现消息提交了，但是还来不及转发biz_topic就宕机的情况，这显然不能容忍。

![image-20240520155442916](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240520155442916.png)

但是如果先转发biz_topic，然后提交。那么提交之前宕机了，后面恢复过来，又会转发一次。好在多发一次并不是什么问题，因为你可以要求业务消费者确保自己的逻辑是幂等的。

![image-20240520155621524](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240520155621524.png)

其实，即便是非延迟消息，还是需要消费者保证自己的逻辑是幂等的，因为本身发送者就存在重复发送的可能，不然没办法确保消息一定投递到消息服务器上。

面试官很可能会为这个一致性的问题，那么你就可以抓住关键词**后提交**来回答。

> ​		一致性的问题解决其来需要业务方的配合，我们这个的逻辑是提交到了延迟时间，就转发biz_topic，然后再提交。也就是说，然后再转发biz_topic之后，提交失败了，下一次就还可以重试，那么biz_topic就可能收到两条同样的消息。在这种场景下，就只能要求消费者做到幂等。当然，即便不用延迟消息，消费者最好也要做到幂等的。因为发送方为了确保发送成功，本身就可能重试。

这个回答可能把话题引申到然后做幂等，后面会有一个高级方案，这里就不多说了。

**优缺点分析**

在回答完前面的两个亮点之后，你要分析一下这个方案的优缺点。

> ​		这个方案最大的优点就是说足够简单，对业务方的影响很小，业务方只需根据自己的延迟时间选择正确的分区就可以了。

不过这个方案也有两个突出的缺点，就是延迟时间必须预先设定好、分区间负载不均匀。

> ​		这个方案的缺点其实还是挺严重的。**第一个是延迟时间必须预先设定好**，比如只能允许延迟1min、3min或者10min的消息，不支持随机延迟时间。在一些业务场景下，需要根据具体业务数据来计算延迟时间，那么这个就不适用 了。**第二个就是分区之间负载不均匀**。比如很多业务可能只需要延迟3min，那么1min和10min分区的数据就很少。这会进一步导致一个问题，**就是负载高的分区会出现消息积压的问题。**
>
> ​		在这里，很多解决消息积压的手段都无法使用，所以只能考虑多设置几个延迟时间相近的分区，不然说在3min附近设置2min30s，3min30s这种分区来分摊压力。

这里你会把话题引导到消息积压如何解决的问题上。

#### 3|消息顺序：保证消息有序，一个_topic_只能有一个partition吗？

在消息队列的相关的面试里面，有序消息和消息不丢失、消息重复消费是三个并列的面试热点，同时在实践中也很容易遇到要求使用有序消息场景。但是大部分人在面试的时候，无法深入透彻的讨论这个问题。大多数时候，只能说出topic只能有一个分区这种最简单的方案。当面试官追问这种方案有什么缺陷的时候就开始答不上来了。



**消息在分区上的组织方式**

在kafka中，消息是以分区为单位进行存储的。分区是逻辑上的概念，用于对消息进行水平划分和并行处理。每个topic都可能划分为一个或多个分区，每个分区都是一个有序、不可变的消息日志。kafka使用WAL（write-ahead-log）日志来存储消息。每个分区都有一个对应的日志文件，新的消息会被追加到文件的末尾，而以及加入日志里的消息，就不会再被修改了。

![image-20240520163243580](https://fwr-typora-img.oss-cn-guangzhou.aliyuncs.com/typroa-img/image-20240520163243580.png)

每个消息在分区日志里都有一个唯一的偏移量（offset），用来标识消息在分区里的位置。

**kafka保证同一个区内的消息顺序，但不保证不同分区之间的顺序。**

而kafka本身暴露了对应的接口，也就是说你可以显式地指定消息要发送到哪个分区，也可以显式地指定消费那个分区的数据。

**什么是有序消息？**

在消息队列里面，有序消息是指消费者消费某个topic消息的顺序，和生产者生产消息的顺序一模一样，它也叫做顺序消息。

前面你应该注意到了，kafka并不能保证不同分区之间的顺序。也就是说，如果业务上有先后顺序的消息被发送到不同